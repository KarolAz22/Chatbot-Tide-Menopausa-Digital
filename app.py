import streamlit as st
import os
import dotenv
from uuid import uuid4
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langgraph.types import Command
from langgraph.checkpoint.memory import InMemorySaver # Necess√°rio para mem√≥ria
from agent.agent import create_agent_graph # Importamos a fun√ß√£o criadora, n√£o o grafo pronto

# 1. CARREGAMENTO DE VARI√ÅVEIS DE AMBIENTE
dotenv.load_dotenv()

REQUIRED_KEYS = ["GOOGLE_API_KEY", "QDRANT_URL", "QDRANT_API_KEY"]

for key in REQUIRED_KEYS:
    if key in st.secrets:
        os.environ[key] = st.secrets[key]

# Configura√ß√£o da P√°gina
st.set_page_config(page_title="Tide - Menopausa Digital", page_icon="ü§ñ", layout="centered")

# --- DEBUG DE AMBIENTE ---
missing_keys = [k for k in REQUIRED_KEYS if not os.getenv(k)]
if missing_keys:
    st.error(f"‚ö†Ô∏è Erro de Configura√ß√£o: Chaves faltando: {', '.join(missing_keys)}")
    st.stop()

# --- INICIALIZA√á√ÉO DO ESTADO ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid4())

# --- INICIALIZA√á√ÉO DO GRAFO (CORRE√á√ÉO DE MEM√ìRIA) ---
if "graph" not in st.session_state:
    # Cria uma mem√≥ria exclusiva para esta sess√£o
    memory = InMemorySaver()
    # Cria o grafo injetando essa mem√≥ria
    st.session_state.graph = create_agent_graph(checkpointer=memory)

config = {"configurable": {"thread_id": st.session_state.thread_id}}

st.title("ü§ñ Tide: Seu Guia Digital da Menopausa")

# --- EXIBI√á√ÉO DO HIST√ìRICO ---
for message in st.session_state.messages:
    if message.get("role") == "tool_log":
        with st.status(message["content"], state="complete"):
            st.write("Consulta realizada.")
    else:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# --- FUN√á√ÉO PRINCIPAL DE EXECU√á√ÉO ---
def run_graph(input_data):
    """Executa o grafo (seja nova mensagem ou resume de interrupt)"""
    
    with st.chat_message("assistant"):
        status_container = st.status("Processando...", expanded=True)
        response_text = ""
        
        try:
            # Usa o grafo armazenado na sess√£o
            # stream_mode="values" retorna a lista completa de mensagens atualizada
            for event in st.session_state.graph.stream(input_data, config, stream_mode="values"):
                
                if "messages" in event and event["messages"]:
                    last_message = event["messages"][-1]
                    
                    # 1. DETECTA USO DE FERRAMENTA
                    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                        for tool_call in last_message.tool_calls:
                            if tool_call["name"] == "retrieve_information":
                                query = tool_call['args'].get('query', 'consulta')
                                status_container.write(f"üîç Pesquisando: *{query}*")
                            elif tool_call["name"] == "send_pdf":
                                status_container.write("üìß Enviando email...")

                    # 2. DETECTA RESPOSTA DA FERRAMENTA
                    if isinstance(last_message, ToolMessage):
                        status_container.write("‚úÖ Dados recebidos.")

                    # 3. DETECTA RESPOSTA FINAL (AI)
                    if isinstance(last_message, AIMessage) and last_message.content:
                        if not last_message.tool_calls:
                            response_text = last_message.content
            
            status_container.update(label="Respondido!", state="complete", expanded=False)
            
            if response_text:
                st.markdown(response_text)
                # Verifica se a mensagem j√° n√£o est√° no hist√≥rico para evitar duplica√ß√£o
                if not st.session_state.messages or st.session_state.messages[-1]["content"] != response_text:
                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                    
        except Exception as e:
            status_container.update(label="Aguardando a√ß√£o...", state="complete", expanded=False)
            # Erros de interrup√ß√£o s√£o normais no LangGraph, n√£o precisamos mostrar erro vermelho
            # print(f"Interrup√ß√£o ou erro: {e}") 

# --- L√ìGICA DE INTERFACE DIN√ÇMICA (INTERRUPTS) ---
# Verifica o estado atual do grafo para ver se parou num interrupt
try:
    state_snapshot = st.session_state.graph.get_state(config)
    
    if state_snapshot.next:
        # Se houver pr√≥ximo passo e estiver parado, √© um interrupt
        current_node = state_snapshot.next[0] if isinstance(state_snapshot.next, tuple) else state_snapshot.next
        
        # === FORMUL√ÅRIOS ===
        if current_node == "personal_questions":
            with st.chat_message("assistant"):
                st.write("üìù **Preciso de alguns dados para continuar:**")
                with st.form("form_pessoal"):
                    nome = st.text_input("Qual √© seu nome?")
                    idade = st.text_input("Qual √© sua idade?") # Melhor ser text para evitar erro de tipo no json
                    email = st.text_input("Qual √© o seu email?")
                    
                    if st.form_submit_button("Enviar Dados"):
                        # CORRE√á√ÉO CR√çTICA: Usamos Command(resume=...) para destravar o interrupt
                        dados = {"nome": nome, "idade": str(idade), "email": email}
                        run_graph(Command(resume=dados))
                        st.rerun()

        elif current_node == "health_questions":
             with st.chat_message("assistant"):
                st.write("ü©∫ **Sobre sua sa√∫de:**")
                with st.form("form_saude"):
                    c1 = st.text_area("Ciclo Menstrual", placeholder="Frequ√™ncia, fluxo...")
                    c2 = st.text_area("Sintomas F√≠sicos", placeholder="Calor√µes, ins√¥nia...")
                    c3 = st.text_area("Sa√∫de Emocional", placeholder="Ansiedade, humor...")
                    c4 = st.text_area("Hist√≥rico e H√°bitos", placeholder="Medicamentos, hist√≥rico familiar...")
                    c5 = st.text_area("Exames e Tratamentos", placeholder="√öltimos exames...")
                    
                    if st.form_submit_button("Gerar Guia"):
                        dados_saude = {
                            "ciclo_menstrual": c1, "sintomas_fisicos": c2,
                            "saude_emocional": c3, "habitos_historico": c4,
                            "exames_tratamentos": c5
                        }
                        run_graph(Command(resume=dados_saude))
                        st.rerun()

        elif current_node == "ask_confirmation":
             with st.chat_message("assistant"):
                st.info("Confirma que os dados est√£o corretos?")
                col1, col2 = st.columns(2)
                if col1.button("‚úÖ Confirmar"):
                    run_graph(Command(resume={"confirmation": True}))
                    st.rerun()
                if col2.button("‚ùå Corrigir"):
                    run_graph(Command(resume={"confirmation": False}))
                    st.rerun()

    # --- CHAT INPUT (S√≥ aparece se N√ÉO estiver num formul√°rio) ---
    else:
        if prompt := st.chat_input("Tire suas d√∫vidas sobre menopausa..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            run_graph({"messages": [HumanMessage(content=prompt)]})

except Exception as e:
    # Caso inicial onde o grafo ainda n√£o rodou nada
    if prompt := st.chat_input("Digite 'ol√°' para come√ßar..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        run_graph({"messages": [HumanMessage(content=prompt)]})