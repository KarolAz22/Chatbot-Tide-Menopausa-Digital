import os
import json
from typing import Literal

from langgraph.prebuilt import ToolNode, tools_condition
from langchain.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.types import interrupt
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel

from agent.utils.prompt import CHAT_SYSTEM_PROMPT, WELCOME_MESSAGE, ROUTER_PROMPT, GUIDE_SYSTEM_PROMPT
from agent.utils.state import StateSchema
from agent.utils.tools import TOOLS_CHAT

MODEL_NAME = "gemini-2.5-flash-lite"

def create_agent_graph(checkpointer=None): #Todo

    llm = ChatGoogleGenerativeAI(
        api_key=os.getenv("GOOGLE_API_KEY"),
        model=MODEL_NAME,
        temperature=0,
        max_tokens=20000,
        timeout=None,
        max_retries=1,            
    )

    graph = StateGraph(state_schema=StateSchema)

    # --- NODES ---

    def welcome_node(state: StateSchema) -> StateSchema:

        state["confirmation"] = False

        return {
            "messages": [AIMessage(content=WELCOME_MESSAGE)]
        }
  

    def router_node(state: StateSchema) -> str:

        class RouterOutput(BaseModel):
            route: str

        system_message = SystemMessage(content=ROUTER_PROMPT)
        
        # OtimizaÃ§Ã£o: A router decide o fluxo macro
        response = llm.with_structured_output(RouterOutput).invoke([system_message, *state["messages"]])

        route = response.route
        if route not in ["chat_node", "guide_node"]:
            route = "chat_node"
            
        return {"route": route}

    def chat_node(state: StateSchema) -> StateSchema:

        system_prompt = SystemMessage(content=CHAT_SYSTEM_PROMPT)
        
        # Bind de ferramentas
        response = llm.bind_tools(tools=TOOLS_CHAT).invoke([system_prompt, *state["messages"]])

        # Normalizar o conteÃºdo da resposta se vier fragmentado (comum em streaming/tools)
        if hasattr(response, 'content') and isinstance(response.content, list):
            text_parts = []
            for item in response.content:
                if isinstance(item, dict) and item.get('type') == 'text':
                    text_parts.append(item.get('text', ''))
                elif isinstance(item, str):
                    text_parts.append(item)
            response.content = ''.join(text_parts)

        return {
            "messages": [response],
        }

    # --- NÃ“S DO FLUXO DE GUIA (Mantidos conforme original) ---
    def guide_node(state: StateSchema) -> StateSchema:

        return {
            "messages": [AIMessage(content="Antes de prosseguirmos, gostaria de fazer algumas perguntas para personalizar melhor o guia para vocÃª.")]
        }
    
    def personal_questions(state: StateSchema) -> StateSchema:

        user_data = state.get("user_data", {})

        questions_prompt = (
            "Por favor, responda as seguintes perguntas pessoais:\n\n"
            "1. Qual Ã© seu nome?\n"
            "2. Qual Ã© sua idade?\n"
            "3. Qual Ã© o seu email? (Usaremos para enviar o guia personalizado)\n\n"
        )
        answer = interrupt(questions_prompt)

        user_data["nome"] = answer.get("nome", "NÃ£o informado")
        user_data["idade"] = answer.get("idade", "NÃ£o informado")
        user_data["email"] = answer.get("email", "NÃ£o informado")
        return {"user_data": user_data}

    def health_questions(state: StateSchema) -> StateSchema:

        user_data = state.get("user_data", {})

        questions_prompt = (
            "Agora, por favor responda as seguintes perguntas sobre sua saÃºde:\n\n"
            "1. Como estÃ¡ o seu ciclo menstrual? Ela tem sido regular em frequÃªncia e fluxo? "
            "VocÃª jÃ¡ completou 12 meses consecutivos sem menstruar?\n\n"
            "2. Quais sintomas fÃ­sicos novos ou incÃ´modos vocÃª tem sentido? "
            "(Por exemplo: ondas de calor, suores noturnos, alteraÃ§Ãµes no sono, cansaÃ§o, ressecamento vaginal, "
            "mudanÃ§as na libido, ganho de peso, queda de cabelo ou infecÃ§Ãµes urinÃ¡rias)\n\n"
            "3. Como vocÃª tem se sentido emocional e mentalmente? "
            "(FlutuaÃ§Ãµes de humor, ansiedade, irritabilidade, desÃ¢nimo, dificuldade de memÃ³ria e concentraÃ§Ã£o)\n\n"
            "4. Como estÃ£o seus hÃ¡bitos de saÃºde e histÃ³rico mÃ©dico? "
            "(Medicamentos ou suplementos que vocÃª usa, histÃ³rico pessoal ou familiar de doenÃ§as crÃ´nicas, "
            "especialmente cÃ¢ncer de mama, rotina de alimentaÃ§Ã£o, exercÃ­cios, consumo de Ã¡lcool ou fumo)\n\n"
            "5. Quando vocÃª realizou seus Ãºltimos exames preventivos e quais tratamentos vocÃª gostaria de discutir? "
            "(Papanicolau, mamografia e densitometria Ã³ssea. VocÃª jÃ¡ tentou algo para os sintomas ou tem interesse "
            "em discutir opÃ§Ãµes, como a terapia de reposiÃ§Ã£o hormonal?)\n\n"
        )

        answer = interrupt(questions_prompt)

        user_data["ciclo_menstrual"] = answer.get("ciclo_menstrual", "NÃ£o informado")
        user_data["sintomas_fisicos"] = answer.get("sintomas_fisicos", "NÃ£o informado")
        user_data["saude_emocional"] = answer.get("saude_emocional", "NÃ£o informado")
        user_data["habitos_historico"] = answer.get("habitos_historico", "NÃ£o informado")
        user_data["exames_tratamentos"] = answer.get("exames_tratamentos", "NÃ£o informado")
        return {"user_data": user_data}

    def show_user_data_node(state: StateSchema) -> StateSchema:
        user_data = state.get("user_data", {}) or {}

        if not user_data:
            content = (
                "Ainda nÃ£o recebi informaÃ§Ãµes suas. Quando estiver pronto, posso fazer as perguntas novamente."
            )
        else:
            header = "Obrigado por fornecer essas informaÃ§Ãµes. Aqui estÃ¡ um resumo dos dados que vocÃª compartilhou:\n"
            sep = "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"

            lines = [header, sep]

            for key, value in user_data.items():
                # torna a chave mais legÃ­vel: 'tempo_menopausa' -> 'Tempo menopausa'
                pretty_key = key.replace("_", " ").capitalize()
                val = ", ".join(f"{k}: {v}" for k, v in value.items()) if isinstance(value, dict) else str(value)
                lines.append(f"â€¢ {pretty_key}: {val}\n")

            lines.append(sep)
            lines.append("Se quiser alterar algum item, clique em ignorar para recomeÃ§ar.")

            content = "\n".join(lines)

        return {"messages": [AIMessage(content=content)]}

        

    def ask_confirmation(state: StateSchema) -> StateSchema:

        question = "Voce confirma que essas informaÃ§Ãµes estÃ£o corretas e completas para prosseguirmos com o guia?"

        answer = interrupt(question)
        return {"confirmation": answer["confirmation"]}

    def generate_guide(state: StateSchema) -> StateSchema:

        user_data = state.get("user_data", {}) or {}

        system_message = SystemMessage(content=GUIDE_SYSTEM_PROMPT)

        # Mapeamento das perguntas feitas ao usuÃ¡rio
        questions_map = {
            "email": "Qual Ã© o seu email? (Usaremos para enviar o guia personalizado)",
            "nome": "Qual Ã© seu nome?",
            "idade": "Qual Ã© sua idade?",
            "ciclo_menstrual": "Como estÃ¡ o seu ciclo menstrual? (Quando foi sua Ãºltima menstruaÃ§Ã£o, ela tem sido regular em frequÃªncia e fluxo? VocÃª jÃ¡ completou 12 meses consecutivos sem menstruar?)",
            "sintomas_fisicos": "Quais sintomas fÃ­sicos novos ou incÃ´modos vocÃª tem sentido? (Por exemplo: ondas de calor, suores noturnos, alteraÃ§Ãµes no sono, cansaÃ§o, ressecamento vaginal, mudanÃ§as na libido, ganho de peso, queda de cabelo ou infecÃ§Ãµes urinÃ¡rias?)",
            "saude_emocional": "Como vocÃª tem se sentido emocional e mentalmente? (VocÃª notou flutuaÃ§Ãµes de humor, ansiedade, irritabilidade, desÃ¢nimo, ou dificuldade de memÃ³ria e concentraÃ§Ã£o?)",
            "habitos_historico": "Como estÃ£o seus hÃ¡bitos de saÃºde e histÃ³rico mÃ©dico? (Incluindo medicamentos ou suplementos que vocÃª usa, seu histÃ³rico pessoal ou familiar de doenÃ§as crÃ´nicas, especialmente cÃ¢ncer de mama, sua rotina de alimentaÃ§Ã£o, exercÃ­cios, consumo de Ã¡lcool ou fumo.)",
            "exames_tratamentos": "Quando vocÃª realizou seus Ãºltimos exames preventivos e quais tratamentos vocÃª gostaria de discutir? (Como Papanicolau, mamografia e densitometria Ã³ssea. VocÃª jÃ¡ tentou algo para os sintomas ou tem interesse em discutir opÃ§Ãµes, como a terapia de reposiÃ§Ã£o hormonal?)"
        }

        prompt_parts = [
            "Crie um guia personalizado de menopausa com base nas seguintes informaÃ§Ãµes coletadas:\n\n"
        ]

        filtered_data = {k: v for k, v in user_data.items() if k != "guide"}

        if not filtered_data or len(filtered_data) == 0:
            # se nÃ£o houver dados, criar um guia genÃ©rico
            prompt_parts.append("InformaÃ§Ãµes do paciente: Dados nÃ£o informados\n")
        else:
            prompt_parts.append("=== PERGUNTAS E RESPOSTAS DA PACIENTE ===\n\n")
            for key, value in filtered_data.items():
                # Adiciona a pergunta correspondente
                question = questions_map.get(key, key.replace("_", " ").capitalize())
                
                if value and value != "NÃ£o informado":
                    prompt_parts.append(f"PERGUNTA: {question}\n")
                    prompt_parts.append(f"RESPOSTA: {value}\n\n")

        prompt_parts.append(
            "\nGere o guia completo seguindo EXATAMENTE o formato especificado no system prompt, "
            "incluindo os marcadores [INICIO_GUIA] e [FIM_GUIA]. "
            "Use as perguntas e respostas acima como contexto para personalizar o guia de forma detalhada e relevante."
        )

        user_message = HumanMessage(content="".join(prompt_parts))

        try:
            response = llm.invoke([system_message, user_message])
            
            if not response or not response.content:
                # Fallback se nÃ£o houver conteÃºdo
                fallback_guide_content = (
                    "# Guia Personalizado para Consulta sobre Menopausa\n\n"
                    "## ðŸ“‹ InformaÃ§Ãµes da Paciente\n"
                    "InformaÃ§Ãµes nÃ£o fornecidas.\n\n"
                    "## ðŸ” Resumo da SituaÃ§Ã£o Atual\n"
                    "Este guia foi criado para ajudÃ¡-la a preparar sua consulta mÃ©dica sobre menopausa.\n\n"
                    "## ðŸ©º Sintomas e ObservaÃ§Ãµes\n"
                    "- Sintomas nÃ£o especificados\n\n"
                    "## â“ Perguntas Importantes para o MÃ©dico\n"
                    "1. Quais sÃ£o os sintomas mais comuns da menopausa?\n"
                    "2. Quais tratamentos estÃ£o disponÃ­veis para mim?\n"
                    "3. Como posso melhorar minha qualidade de vida durante este perÃ­odo?\n"
                    "4. Existem mudanÃ§as no estilo de vida que vocÃª recomenda?\n"
                    "5. Quando devo retornar para acompanhamento?\n\n"
                    "## ðŸ’¡ RecomendaÃ§Ãµes de Bem-Estar\n"
                    "- Mantenha uma alimentaÃ§Ã£o equilibrada rica em cÃ¡lcio e vitamina D\n"
                    "- Pratique exercÃ­cios fÃ­sicos regularmente\n"
                    "- Cuide da saÃºde mental e busque apoio quando necessÃ¡rio\n"
                    "- Mantenha-se hidratada\n\n"
                    "## ðŸ“Œ PrÃ³ximos Passos\n"
                    "- Anote qualquer sintoma novo antes da consulta\n"
                    "- Leve este guia impresso ou em formato digital\n"
                    "- NÃ£o hesite em fazer todas as suas perguntas ao mÃ©dico\n\n"
                    "---\n"
                    "*Este guia foi gerado para auxiliar na preparaÃ§Ã£o da sua consulta mÃ©dica.*"
                )
                
                full_response = (
                    f"[INICIO_GUIA]\n{fallback_guide_content}\n[FIM_GUIA]\n\n"
                    "Pronto! Seu guia personalizado foi gerado com sucesso! ðŸ“‹âœ¨ "
                    "Gostaria que eu enviasse este guia para o seu email?"
                )
                
                response = AIMessage(content=full_response)
            
            content = response.content
            guide_content = content
            
            if "[INICIO_GUIA]" in content and "[FIM_GUIA]" in content:
                start_idx = content.find("[INICIO_GUIA]") + len("[INICIO_GUIA]")
                end_idx = content.find("[FIM_GUIA]")
                guide_content = content[start_idx:end_idx].strip()
            
            if "user_data" not in state:
                state["user_data"] = {}
            state["user_data"]["guide"] = guide_content

            return {
                "messages": [response],
                "user_data": state["user_data"]
            }
        
        except Exception as e:
            #print(f"[ERROR] Erro ao gerar guia: {str(e)}")
           
            error_message = AIMessage(
                content=f"Desculpe, houve um problema ao gerar o guia. Por favor, tente novamente mais tarde. Se o problema persistir, entre em contato com o suporte."
            )
            return {
                "messages": [error_message],
                "user_data": state.get("user_data", {})
            }

    tool_node = ToolNode(tools=TOOLS_CHAT, name="tools_chat")
    
    graph.add_node("welcome_node", welcome_node)
    graph.add_node("chat_node", chat_node)
    graph.add_node("tools_chat", tool_node)
    graph.add_node("router_node", router_node)
    graph.add_node("guide_node", guide_node)
    graph.add_node("personal_questions", personal_questions)
    graph.add_node("health_questions", health_questions)
    graph.add_node("show_user_data_node", show_user_data_node)
    graph.add_node("ask_confirmation", ask_confirmation)
    graph.add_node("generate_guide", generate_guide)



   
    # DefiniÃ§Ã£o de arestas
    graph.add_edge("welcome_node", END)

    # Fluxo Router
    def route_condition(state: StateSchema) -> Literal["chat_node", "guide_node"]:
        if state.get("route") == "chat_node":
            return "chat_node"
        return "guide_node"

    graph.add_conditional_edges("router_node", route_condition)

    # Fluxo Chat (OTIMIZADO)
    # Aqui removemos a lÃ³gica de avaliaÃ§Ã£o. Se usar tool, vai pra tool. Se nÃ£o, encerra a rodada.
    graph.add_conditional_edges(
        "chat_node", 
        tools_condition, 
        {"tools": "tools_chat", "__end__": END}
    )
    graph.add_edge("tools_chat", "chat_node")

    # Fluxo Guia (Linear)
    graph.add_edge("guide_node", "personal_questions")
    graph.add_edge("personal_questions", "health_questions")
    graph.add_edge("health_questions", "show_user_data_node")
    graph.add_edge("show_user_data_node", "ask_confirmation")



    def data_condition(state: StateSchema) -> Literal["personal_questions", "generate_guide"]:
        if state.get("confirmation"):
            return "generate_guide"
        return "personal_questions"

    graph.add_conditional_edges("ask_confirmation", data_condition)
    def welcome_condition(state:  StateSchema) -> Literal["router_node", "welcome_node"]:

        if len(state["messages"]) <= 1:
            return "welcome_node"
        else:
            return "router_node"

    graph.add_conditional_edges(START, welcome_condition)

    graph.add_edge("generate_guide", END)

    return graph.compile(checkpointer=checkpointer) #Todo

graph = create_agent_graph()